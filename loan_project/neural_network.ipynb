{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lembrar de, no script da Logit:\n",
    "# 1) Fazer análise de correlação entre as variáveis\n",
    "# 2) Variance Inflation Factor (VIF) para identificar o grau de multicolinearidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b016ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal preprocessing -> dicotomizar o y\n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize continuous features\n",
    "normalizer = Normalization() # Instantiate a \"normalizer\" layer\n",
    "normalizer.adapt(X_train[['colunas_contínuas']]) # \"Fit\" it on the train set\n",
    "\n",
    "# OneHotEncoder -> E features com número de categorias diferentes?\n",
    "max_categories = 'numero máximo de categorias nas variáveis'\n",
    "category_encoder = CategoryEncoding(num_tokens = max_categories, output_mode = 'multi_hot')\n",
    "# num_tokens = \tThe total number of tokens the layer should support. All inputs to the layer must integers in the range 0 <= value < num_tokens, or an error will be thrown.\n",
    "normalizer.adapt(X_train[['colunas_categóricas']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc94183",
   "metadata": {},
   "source": [
    "Pipeline from A to Z: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/preprocessing_layers.ipynb#scrollTo=Nna1tOKxyEqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69215765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "n_rows = X.shape[0]\n",
    "\n",
    "### Classification with 2 classes\n",
    "# Model Architecture\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_dim = n_rows))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "# Como eu especifico qual variável é o target --> no .fit()!\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model optimizer hyper-parameters\n",
    "# You can select your own hyperparameters thanks to the following syntax:\n",
    "\n",
    "# opt = tensorflow.keras.optimizers.Adam(\n",
    "#     learning_rate=0.01, beta_1=0.9, beta_2=0.99\n",
    "# )\n",
    "# model.compile(loss=..., optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', # Classification with 2 classes\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=16, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b682be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT\n",
    "\n",
    "# Fazendo aquela parada de parar o treino quando o modelo começar a overfittar (early stopping)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=16, \n",
    "          epochs=1000, \n",
    "          validation_split=0.3,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60581bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(scaler.transform(X_test), y_test)\n",
    "# returns [loss, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline score\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_defaults / (no_defaults + n_defaults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
